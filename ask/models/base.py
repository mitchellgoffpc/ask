import json
from abc import ABCMeta, abstractmethod
from dataclasses import dataclass
from typing import Any, AsyncIterator, Optional, Union

from ask.tools import Tool, ToolCallStatus

COMMAND_PROMPT = """
Caveat: The messages below were generated by the user while running local commands.
DO NOT respond to these messages or otherwise consider them in your response unless the user explicitly asks you to.
""".strip().replace('\n', ' ')

Content = Union['Error', 'Text', 'Reasoning', 'Image', 'ToolRequest', 'ToolResponse', 'AppCommand', 'ShellCommand', 'Usage']

def get_message_groups(messages: list['Message']) -> list[tuple[str, list[Content]]]:
    if not messages:
        return []
    groups = []
    current_role = messages[0].role
    current_group = [messages[0].content]
    for message in messages[1:]:
        if message.role == current_role:
            current_group.append(message.content)
        else:
            groups.append((current_role, current_group))
            current_role = message.role
            current_group = [message.content]
    return groups + [(current_role, current_group)]


# Message classes

@dataclass
class Message:
    role: str
    content: Content

@dataclass
class Text:
    text: str

@dataclass
class Reasoning:
    text: str
    encrypted: bool = False

@dataclass
class Image:
    mimetype: str
    data: bytes

@dataclass
class ToolRequest:
    call_id: str
    tool: str
    arguments: dict[str, str]
    processed_arguments: dict[str, str] | None = None

@dataclass
class ToolResponse:
    call_id: str
    tool: str
    response: str
    status: ToolCallStatus

@dataclass
class AppCommand:
    command: str
    output: str

@dataclass
class ShellCommand:
    command: str
    stdout: str = ''
    stderr: str = ''
    status: ToolCallStatus = ToolCallStatus.PENDING

@dataclass
class Error:
    text: str

@dataclass
class Usage:
    input: int
    cache_write: int
    cache_read: int
    output: int
    model: Optional['Model'] = None


# Model / API classes

@dataclass
class Pricing:
    input: float
    cache_write: float
    cache_read: float
    output: float

@dataclass
class Model:
    name: str
    api: 'API'
    shortcuts: list[str]
    pricing: Pricing | None = None
    stream: bool = True
    supports_tools: bool = True
    supports_images: bool = True
    supports_system_prompt: bool = True


class API(metaclass=ABCMeta):
    def __init__(self, url: str, key: str):
        self.key = key
        self.base_url = url

    # Rendering

    @abstractmethod
    def render_text(self, text: Text) -> dict[str, Any]: ...

    def render_response_text(self, text: Text) -> dict[str, Any]:
        return self.render_text(text)

    @abstractmethod
    def render_image(self, image: Image) -> dict[str, Any]: ...

    @abstractmethod
    def render_reasoning(self, reasoning: Reasoning) -> dict[str, Any]: ...

    @abstractmethod
    def render_tool_request(self, request: ToolRequest) -> dict[str, Any]: ...

    @abstractmethod
    def render_tool_response(self, response: ToolResponse) -> dict[str, Any]: ...

    def render_app_command(self, command: AppCommand) -> list[dict[str, Any]]:
        return [
            self.render_text(Text(COMMAND_PROMPT)),
            self.render_text(Text(f"<local-command>{command.command}</local-command>")),
            self.render_text(Text(f"<local-command-output>\n{command.output}\n</local-command-output>"))]

    def render_shell_command(self, command: ShellCommand) -> list[dict[str, Any]]:
        if command.status is ToolCallStatus.CANCELLED:
            output = "[Request interrupted by user]"
        else:
            output = f"<bash-stdout>\n{command.stdout}\n</bash-stdout>\n<bash-stderr>\n{command.stderr}\n</bash-stderr>"
        return [
            self.render_text(Text(COMMAND_PROMPT)),
            self.render_text(Text(f"<bash-stdin>{command.command}</bash-stdin>")),
            self.render_text(Text(output))]

    def render_content(self, role: str, content: Content, model: Model) -> list[dict[str, Any]]:
        if isinstance(content, Usage):
            return []
        elif isinstance(content, Text):
            return [self.render_response_text(content) if role == 'assistant' else self.render_text(content)]
        elif isinstance(content, Image):
            if not model.supports_images:
                raise NotImplementedError(f"Model '{model.name}' does not support image prompts")
            return [self.render_image(content)]
        elif isinstance(content, ToolRequest):
            return [self.render_tool_request(content)]
        elif isinstance(content, ToolResponse):
            return [self.render_tool_response(content)]
        elif isinstance(content, AppCommand):
            return self.render_app_command(content)
        elif isinstance(content, ShellCommand):
            return self.render_shell_command(content)
        elif isinstance(content, Reasoning):
            return [self.render_reasoning(content)]
        else:
            raise TypeError(f"Unsupported message content: {type(content)}")

    @abstractmethod
    def render_tool(self, tool: Tool) -> dict[str, Any]: ...

    # Request / Response

    def url(self, model: Model, stream: bool) -> str:
        return self.base_url

    @abstractmethod
    def headers(self, api_key: str) -> dict[str, str]: ...

    @abstractmethod
    def params(self, model: Model, messages: list[Message], tools: list[Tool], system_prompt: str, stream: bool) -> dict[str, Any]: ...

    @abstractmethod
    def result(self, response: dict[str, Any]) -> list[Content]: ...

    async def decode(self, chunks: AsyncIterator[str]) -> AsyncIterator[tuple[str, Content | None]]:
        current_idx, current_tool = '', ''
        current_data: list[str] = []
        current_usage: Usage | None = None
        async for chunk in chunks:
            idx, tool, data, usage = self.decode_chunk(chunk)
            if idx and idx != current_idx:
                yield self.flush_content(current_idx, idx, current_tool, ''.join(current_data))
                current_idx, current_tool, current_data = idx, '', []
            current_usage = usage or current_usage
            current_tool = tool or current_tool
            current_data.append(data)
            if not current_tool:
                yield data, None
        yield self.flush_content(current_idx, '', current_tool, ''.join(current_data))
        if current_usage:
            yield '', current_usage

    @abstractmethod
    def decode_chunk(self, chunk: str) -> tuple[str, str, str, Usage | None]: ...

    def flush_content(self, current_idx: str, next_idx: str, tool: str, data: str) -> tuple[str, Content | None]:
        if tool == '/reasoning':
            return '', Reasoning(text=data, encrypted=True)
        elif tool:
            assert ':' in tool, "Expected tool to be formatted as <name>:<call-id>"
            tool_name, call_id = tool.rsplit(':', 1)
            return '', ToolRequest(call_id=call_id, tool=tool_name, arguments=json.loads(data))
        elif data:
            return '', Text(text=data)
        else:
            return '', None
